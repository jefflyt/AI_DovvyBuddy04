ENVIRONMENT=development
DEBUG=true
API_HOST=0.0.0.0
API_PORT=8000

# CORS Configuration for Frontend Integration
# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,https://dovvybuddy.com
# Optional: Regex pattern for dynamic origins (e.g., Vercel preview deployments)
CORS_ORIGIN_REGEX=https://.*\.vercel\.app

DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/dovvybuddy
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# API Keys
GEMINI_API_KEY=your_gemini_api_key_here
GROQ_API_KEY=your_groq_api_key_here

# LLM Provider Configuration
DEFAULT_LLM_PROVIDER=groq                  # groq | gemini
DEFAULT_LLM_MODEL=gemini-2.0-flash         # Model name (Gemini standard per copilot-instructions.md)
LLM_TEMPERATURE=0.7                        # Generation temperature (0.0-1.0)
LLM_MAX_TOKENS=2048                        # Maximum tokens per generation

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-004         # Gemini embedding model (768 dimensions)
EMBEDDING_BATCH_SIZE=100                   # Max texts per batch request
EMBEDDING_CACHE_SIZE=1000                  # In-memory cache size
EMBEDDING_CACHE_TTL=3600                   # Cache TTL in seconds (1 hour)

# RAG Configuration
ENABLE_RAG=true                            # Enable/disable RAG pipeline
RAG_TOP_K=5                                # Number of chunks to retrieve
RAG_MIN_SIMILARITY=0.5                     # Minimum cosine similarity threshold
RAG_CHUNK_SIZE=512                         # Target chunk size in tokens (not used in chunker yet)
RAG_CHUNK_OVERLAP=50                       # Token overlap between chunks (not used in chunker yet)

# Retry Configuration
LLM_MAX_RETRIES=3                          # Max retry attempts for LLM calls
LLM_RETRY_DELAY=1.0                        # Initial retry delay (seconds)
EMBEDDING_MAX_RETRIES=3                    # Max retry attempts for embeddings
EMBEDDING_RETRY_DELAY=1.0                  # Initial retry delay (seconds)

# Orchestration Configuration
MAX_MESSAGE_LENGTH=2000                    # Maximum user message length
SESSION_EXPIRY_HOURS=24                    # Session expiry time
MAX_CONVERSATION_HISTORY=20                # Max messages to keep in history
ENABLE_AGENT_ROUTING=true                  # Enable intelligent agent routing
DEFAULT_AGENT=retrieval                    # Default agent if mode unclear

# PR6.1: Conversation Continuity Feature
# Enable intent-driven follow-up questions for conversation continuity
# Default: false (gradual rollout, disable for instant rollback)
FEATURE_CONVERSATION_FOLLOWUP_ENABLED=false

# Lead Capture & Delivery Configuration
# Required: API key from Resend dashboard (https://resend.com/api-keys)
RESEND_API_KEY=re_xxxxxxxxxxxx
# Required: Destination email for lead notifications
LEAD_EMAIL_TO=leads@diveshop.com
# Optional: Sender email (requires domain verification at https://resend.com/domains)
# Defaults to leads@dovvybuddy.com if not set
LEAD_EMAIL_FROM=leads@dovvybuddy.com
# Optional: Webhook endpoint for CRM integration (future feature)
LEAD_WEBHOOK_URL=

# Prompt Configuration
SYSTEM_PROMPT_VERSION=v1                   # System prompt version (for A/B testing)
INCLUDE_SAFETY_DISCLAIMER=true             # Always include safety disclaimer

# Legacy (for reference, not used by Python backend yet)
CONTENT_DIR=../content
